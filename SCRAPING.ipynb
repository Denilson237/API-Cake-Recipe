{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90709170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6423953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n"
     ]
    }
   ],
   "source": [

    "BASE_URL = \"https://www.cuisine-libre.org/\"\n",
    "JSON_FILENAME = \"Recette.json\"\n",
    "JSON_EXCLUDE_FILENAME = \"recettes_a_exclure.json\"\n",
    "\n",
    "def telecharger_et_sauvegarder_image(url,name):\n",
    "    response = requests.get(url)\n",
    "    filenmame = f\"IMAGES/{name}.jpg\"\n",
    "    if response.status_code == 200:\n",
    "        with open(filenmame, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "\n",
    "def nettoyer_texte(t):\n",
    "    return t.replace(\"\\xa0\", \" \").replace(\"\\n\", \"\").strip()\n",
    "\n",
    "\n",
    "def extraire_duree_recette(recipe_infos_p, class_name):\n",
    "    span = recipe_infos_p.find(\"span\", class_=class_name)\n",
    "    duree = span.find(\"time\").text if span else \"\"\n",
    "    return nettoyer_texte(duree).replace(\"?\", \"\")\n",
    "\n",
    "\n",
    "def extraire_infos_recette(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "    titre = nettoyer_texte(str(soup.find(\"h1\").contents[0]))\n",
    "\n",
    "    recipe_infos_p = soup.find(\"p\", id=\"recipe-infos\")\n",
    "    # \"article-duree_preparation-1383\"\n",
    "    # duree_preparation = recipe_infos_p.find(\"time\", class_=lambda x: x and x.startswith(\"article-duree_preparation-\")).text\n",
    "    duree_preparation = extraire_duree_recette(recipe_infos_p, \"duree_preparation\")\n",
    "    duree_cuisson = extraire_duree_recette(recipe_infos_p, \"duree_cuisson\")\n",
    "    duree_repos = extraire_duree_recette(recipe_infos_p, \"duree_repos\")\n",
    "    methode_cuisson_a = recipe_infos_p.find(\"a\")\n",
    "    methode_cuisson = methode_cuisson_a.text if methode_cuisson_a else \"\"\n",
    "\n",
    "    infos = {\"duree_preparation\": duree_preparation,\n",
    "             \"duree_cuisson\": duree_cuisson,\n",
    "             \"duree_repos\": duree_repos,\n",
    "             \"methode_cuisson\": methode_cuisson}\n",
    "\n",
    "    div_ingredients = soup.find(\"div\", id=\"ingredients\")\n",
    "    ingredients_li = div_ingredients.find_all(\"li\", class_=\"ingredient\")\n",
    "    ingredients = [nettoyer_texte(i.text) for i in ingredients_li if not i.find(\"i\")]\n",
    "\n",
    "    div_preparation = soup.find(\"div\", id=\"preparation\")\n",
    "    items_preparation = div_preparation.find_all(\"p\")\n",
    "    if len(items_preparation) == 0:\n",
    "        items_preparation = div_preparation.find_all(\"li\")\n",
    "    etapes = [nettoyer_texte(i.text) for i in items_preparation]\n",
    "\n",
    "    recette = {\"titre\": titre,\n",
    "               \"infos\": infos,\n",
    "               \"ingredients\": ingredients,\n",
    "               \"etapes\": etapes}\n",
    "\n",
    "    return recette\n",
    "\n",
    "def extraire_liste_recettes(url, urls_exclues = None):\n",
    "    # { \"titre\": \"\", \"url\": \"\", \"url_image\": \"\" }\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    div_recettes = soup.find(\"div\", id=\"recettes\")\n",
    "    ul_recettes = div_recettes.find(\"ul\", recursive=False)\n",
    "    li_recettes = ul_recettes.find_all(\"li\")\n",
    "\n",
    "    nouvelles_urls_a_exclure = []\n",
    "\n",
    "    liste_resultats = []\n",
    "    for li in li_recettes:\n",
    "        a = li.find(\"a\")\n",
    "        strong = a.find(\"strong\")\n",
    "        titre = nettoyer_texte(strong.text)\n",
    "        url = BASE_URL + a[\"href\"]\n",
    "        img = a.find(\"img\")\n",
    "        url_image = BASE_URL + img[\"src\"]\n",
    "\n",
    "        if not(urls_exclues and url in urls_exclues):\n",
    "            recette = extraire_infos_recette(url)\n",
    "            if recette:\n",
    "                liste_resultats.append({\"titre\": titre, \"url\": url, \"url_image\": url_image, \"recette\": recette})\n",
    "            else:\n",
    "                nouvelles_urls_a_exclure.append(url)\n",
    "\n",
    "    return liste_resultats, nouvelles_urls_a_exclure\n",
    "\n",
    "# Charger les données\n",
    "\n",
    "def charger_fichier_json(filename):\n",
    "    if os.path.exists(filename):\n",
    "        f = open(filename, \"r\")\n",
    "        json_data = f.read()\n",
    "        f.close()\n",
    "        return json.loads(json_data)\n",
    "    return None\n",
    "\n",
    "def sauvegarder_fichier_json(filename, data):\n",
    "    json_data = json.dumps(data)\n",
    "    f = open(filename, \"w\")\n",
    "    f.write(json_data)\n",
    "    f.close()\n",
    "\n",
    "liste_recettes_sauvegardees = charger_fichier_json(JSON_FILENAME)\n",
    "if not liste_recettes_sauvegardees:\n",
    "    liste_recettes_sauvegardees = []\n",
    "\n",
    "urls_recettes_a_exlure_sauvegardees = charger_fichier_json(JSON_EXCLUDE_FILENAME)\n",
    "if not urls_recettes_a_exlure_sauvegardees:\n",
    "    urls_recettes_a_exlure_sauvegardees = []\n",
    "\n",
    "urls_recettes_a_exlure = [r[\"url\"] for r in liste_recettes_sauvegardees]\n",
    "urls_recettes_a_exlure.extend(urls_recettes_a_exlure_sauvegardees)\n",
    "\n",
    "liste_recettes, nouvelles_urls_recettes_a_exlure = extraire_liste_recettes(\"https://www.cuisine-libre.org/boulangerie-et-patisserie?mots%5B%5D=83&lang=&max=270\",\n",
    "                                         urls_recettes_a_exlure)\n",
    "\n",
    "liste_recettes_sauvegardees.extend(liste_recettes)\n",
    "liste_recettes = liste_recettes_sauvegardees\n",
    "\n",
    "print(len(liste_recettes))\n",
    "\n",
    "# données -> sérialise en JSON -> Texte\n",
    "# texte -> désérialise le JSON -> données\n",
    "\n",
    "# Sauvegarder les données\n",
    "sauvegarder_fichier_json(JSON_FILENAME, liste_recettes)\n",
    "\n",
    "urls_recettes_a_exlure_sauvegardees.extend(nouvelles_urls_recettes_a_exlure)\n",
    "\n",
    "\n",
    "for r in liste_recettes:\n",
    "    telecharger_et_sauvegarder_image(r[\"url_image\"], r[\"titre\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546030c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
